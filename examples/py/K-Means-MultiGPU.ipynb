{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "!nvidia-smi\n",
    "import sys\n",
    "print(sys.path)\n",
    "import py3nvml ## pip install -e git+https://github.com/fbcotter/py3nvml#egg=py3nvml\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o4gpu as h2o4gpu\n",
    "maxNGPUS = int(subprocess.check_output(\"nvidia-smi -L | wc -l\", shell=True))\n",
    "print(\"\\nNumber of GPUS:\", maxNGPUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "train_file = home + \"/h2o4gpu-benchmarks/Data/Homesite/train.csv\"\n",
    "test_file = home + \"/h2o4gpu-benchmarks/Data/Homesite/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_file)\n",
    "test = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(['QuoteConversion_Flag'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.concat([train,test], ignore_index = True)\n",
    "tmp = dataset.dtypes.reset_index().rename(columns = {0:\"type\"})#[\"index\"]\n",
    "indx = tmp[\"type\"] == \"object\"\n",
    "categoricals = tmp[indx][\"index\"].tolist()\n",
    "\n",
    "#replace nans as new category\n",
    "for col in dataset.columns:\n",
    "    dataset[col] = dataset[col].fillna(\"__NA__\")\n",
    "\n",
    "#encode unfreq categories\n",
    "for col in categoricals:\n",
    "    val_dict = dataset[col].value_counts()\n",
    "    val_dict = dataset[col].value_counts().reset_index()\n",
    "    indx = val_dict[col] < 100\n",
    "    res = val_dict[indx][\"index\"].tolist()\n",
    "    indx = dataset[col].isin(res)\n",
    "    vals = dataset[col].values\n",
    "    vals[indx] = \"___UNFREQ___\"\n",
    "    dataset[col] = vals\n",
    "    \n",
    "#encode all as freqs\n",
    "for col in categoricals:\n",
    "    val_dict = dataset[col].value_counts()\n",
    "    val_dict = val_dict / float(dataset.shape[0])\n",
    "    val_dict = val_dict.to_dict()\n",
    "    dataset[col] = dataset[col].apply(lambda x: val_dict[x])\n",
    "    \n",
    "#replace nans as new category\n",
    "for col in dataset.columns:\n",
    "    dataset[col] = dataset[col].replace(\"__NA__\",0)\n",
    "    \n",
    "trainenc = dataset.iloc[:train.shape[0],:].reset_index(drop = True)\n",
    "testenc = dataset.iloc[train.shape[0]:,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainencflt = trainenc.values.astype(np.float32)\n",
    "testencflt = testenc.values.astype(np.float32)\n",
    "k=1000\n",
    "rows=np.shape(trainencflt)[0]\n",
    "print(rows)\n",
    "np.random.seed(1234)\n",
    "#labels = np.random.randint(rows, size=rows) % k\n",
    "import random\n",
    "import numpy as np\n",
    "labels=np.asarray([])\n",
    "num=int(rows/k)\n",
    "for x in range(0, num+1):\n",
    "    if x<num:\n",
    "        many=k\n",
    "    else:\n",
    "        many=rows%k\n",
    "    labels = np.append(labels,np.asarray(random.sample(range(k), many)))\n",
    "#print(labels)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2O4GPU K-Means (multi-GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpus = 1\n",
    "model = h2o4gpu.KMeans(n_gpus=n_gpus, n_clusters=k, tol=1e-7, max_iter=1000)\n",
    "%time model.fit(trainencflt, labels)\n",
    "centroids = model.cluster_centers_\n",
    "#%time train_centroid_distance = model.transform(trainencflt)\n",
    "#%time train_labels     = model.predict(trainencflt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2O4GPU K-Means (multi-GPU with restrictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=1 # all gpus=0 and pick device=1,2,3...\n",
    "model = h2o4gpu.KMeans(n_gpus=2, gpu_id=device, n_clusters=k, init=\"random\", tol=1e-10, max_iter=1000, verbosity=1)\n",
    "%time model.fit(trainencflt)\n",
    "#%time train_centroid_distance2 = model.transform(trainencflt)\n",
    "#%time train_labels = model.predict(trainencflt)\n",
    "\n",
    "#%time test_centroid_distance  = model.transform(testencflt)\n",
    "#%time test_labels     = model.predict(testencflt)\n",
    "\n",
    "## 60s for 224 iters (stopped early) ==> 268s for 1000 iters\n",
    "## 51s for 216 iters (stopped early) on mr-dl10\n",
    "## 49s for 165 iters (stopped early) on physics-179.umd.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "h2o.init(strict_version_check=False)\n",
    "h2otrain = h2o.import_file(train_file)\n",
    "h2otest = h2o.import_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.kmeans import H2OKMeansEstimator\n",
    "h2omodel = H2OKMeansEstimator(k=k, standardize=False, max_iterations=50, init=\"Random\")\n",
    "%time h2omodel.train(training_frame=h2otrain)\n",
    "\n",
    "## 600 s for 50 iters -> 12000 secs for 1000 iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%time trainassignments=h2omodel.predict(h2otrain)\n",
    "#hist(trainassignments.as_data_frame().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%time testassignments=h2omodel.predict(h2otest)\n",
    "#hist(testassignments.as_data_frame().values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(algorithm='full',n_clusters=k, init='random', n_init=1, n_jobs=-1, max_iter=50, tol=1e-8,verbose=1)\n",
    "%time model.fit(trainencflt)\n",
    "#train_assignments = model.predict(trainencflt)\n",
    "#test_assignments = model.predict(testencflt)\n",
    "\n",
    "## 58s for 50 iters -> 1160s for 1000 iters\n",
    "## 111s for 50 iterations (physics-179.umd.edu with defualt pip installed scikit-learn)\n",
    "## 123s for 50 iterations (physics-179.umd.edu with MKL in scikit-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "from tensorflow.contrib.learn import KMeansClustering\n",
    "from tensorflow.contrib.learn import SKCompat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    return (tf.constant(trainencflt, shape = [trainencflt.shape[0], trainencflt.shape[1]]), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seed = 12345\n",
    "model = KMeansClustering(num_clusters=1000, \n",
    "                         initial_clusters=KMeansClustering.RANDOM_INIT, \n",
    "                         relative_tolerance=1e-8,\n",
    "                         random_seed = seed)\n",
    "t0 = time.time()\n",
    "model.fit(input_fn = train_input_fn, steps = 100)\n",
    "t1 = time.time()\n",
    "print(\"TF time taken: %r\" % (t1 - t0))\n",
    "\n",
    "## 132s for 100 iters ==> 1320s for 1000 iters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: TensorFlow detects the GPUs, but the GPUs aren't doing much compute\n",
    "```\n",
    "2017-06-18 17:01:26.394132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: \n",
    "name: TITAN X (Pascal)\n",
    "major: 6 minor: 1 memoryClockRate (GHz) 1.531\n",
    "pciBusID 0000:01:00.0\n",
    "Total memory: 11.90GiB\n",
    "Free memory: 10.48GiB\n",
    "2017-06-18 17:01:26.639874: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x19507e00 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.\n",
    "2017-06-18 17:01:26.640842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 1 with properties: \n",
    "name: GeForce GTX 1080 Ti\n",
    "major: 6 minor: 1 memoryClockRate (GHz) 1.582\n",
    "pciBusID 0000:02:00.0\n",
    "Total memory: 10.91GiB\n",
    "Free memory: 10.75GiB\n",
    "2017-06-18 17:01:26.899156: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x19503f60 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.\n",
    "2017-06-18 17:01:26.900102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 2 with properties: \n",
    "name: GeForce GTX 1080 Ti\n",
    "major: 6 minor: 1 memoryClockRate (GHz) 1.582\n",
    "pciBusID 0000:03:00.0\n",
    "Total memory: 10.91GiB\n",
    "Free memory: 10.75GiB\n",
    "2017-06-18 17:01:26.902241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 1 2 \n",
    "2017-06-18 17:01:26.902254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y Y Y \n",
    "2017-06-18 17:01:26.902259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 1:   Y Y Y \n",
    "2017-06-18 17:01:26.902263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 2:   Y Y Y \n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "Sun Jun 18 17:12:59 2017       \n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 381.22                 Driver Version: 381.22                    |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  TITAN X (Pascal)    On   | 0000:01:00.0      On |                  N/A |\n",
    "|100%   40C    P2    56W / 250W |  11694MiB / 12188MiB |      1%      Default |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   1  GeForce GTX 108...  On   | 0000:02:00.0     Off |                  N/A |\n",
    "| 90%   33C    P8    20W / 250W |  10622MiB / 11172MiB |      0%      Default |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   2  GeForce GTX 108...  On   | 0000:03:00.0     Off |                  N/A |\n",
    "| 80%   32C    P8    19W / 250W |  10622MiB / 11172MiB |      0%      Default |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "                                                                               \n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                       GPU Memory |\n",
    "|  GPU       PID  Type  Process name                               Usage      |\n",
    "|=============================================================================|\n",
    "|    0      2309    G   /usr/lib/xorg/Xorg                             738MiB |\n",
    "|    0      2747    G   compiz                                         467MiB |\n",
    "|    0     25319    C   ...yenv/versions/3.6.0/envs/h2o4gpu/bin/python 10335MiB |\n",
    "|    0     30919    G   ...el-token=798A69B792D7683DCFF8AA9AA8F4DFD9   141MiB |\n",
    "|    1     25319    C   ...yenv/versions/3.6.0/envs/h2o4gpu/bin/python 10611MiB |\n",
    "|    2     25319    C   ...yenv/versions/3.6.0/envs/h2o4gpu/bin/python 10611MiB |\n",
    "+-----------------------------------------------------------------------------+\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
