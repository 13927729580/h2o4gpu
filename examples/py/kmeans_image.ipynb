{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stepdata=1 # sparsify data before computing\n",
    "k=21 # choose number of clusters\n",
    "maxiterations=1000 # number of iterations\n",
    "whichalgo=1 # which algorithm\n",
    "whichimage=0 # which image to start with\n",
    "doubleprecision=0 # if double precision or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# also control \"step\" that sets how much of final plot to show (too many points takes too long even if kmeans if fast)\n",
    "if whichimage==0:\n",
    "    logo = Image.open(\"h2o-logo.jpg\");step=13\n",
    "if whichimage==1: \n",
    "    logo = Image.open(\"low_h2o-logo.jpg\");step=2\n",
    "if whichimage==2:\n",
    "    logo = Image.open(\"lowlow_h2o-logo.jpg\");step=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = array(logo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = int(data.shape[0]*data.shape[1]/2)\n",
    "seed(777)\n",
    "space = concatenate((randint(0, data.shape[0], N)[:, newaxis], randint(0, data.shape[1], N)[:, newaxis]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uspace = zeros_like(data)\n",
    "uspace[space[:, 0], space[:, 1]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(uspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dots = data * uspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(dots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = vstack(nonzero(dots)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#numpy.set_printoptions(threshold=numpy.nan)\n",
    "#print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[::stepdata]    \n",
    "np.isfortran(dataset)\n",
    "print(type (dataset))\n",
    "print(dataset.shape)\n",
    "\n",
    "rows=np.shape(dataset)[0]\n",
    "print(\"rows=%d\" % (rows))\n",
    "labels = np.random.randint(rows, size=rows) % k\n",
    "\n",
    "if doubleprecision==1:\n",
    "    dataset = dataset.astype(float64)\n",
    "    labels = labels.astype(float32)\n",
    "else:\n",
    "    dataset = dataset.astype(float32)\n",
    "    labels = labels.astype(float32)\n",
    "\n",
    "for i in range(k):\n",
    "    print(i in labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if whichalgo==0:\n",
    "    import libKMCUDA\n",
    "    %time cents, asses = libKMCUDA.kmeans_cuda(dataset, k, seed=77, device=0, yinyang_t=0,tolerance=1e-3,verbosity=1)\n",
    "    # 3m25s on 1 titanX pascal with stepdata=1 , k=21 , maxiterations=1000 , whichalgo=0 , whichimage=0\n",
    "if whichalgo==1:\n",
    "    import h2ogpuml\n",
    "    rows=np.shape(dataset)[0]\n",
    "    np.random.seed(1234)\n",
    "    n_gpus=1\n",
    "    init_from_labels=0 # so auto-generate initial centroids, no need to initialize labels or centroids\n",
    "    model = h2ogpuml.KMeans(n_gpus=n_gpus, n_clusters=k, tol=1e-7, max_iter=maxiterations,init_from_labels=init_from_labels)\n",
    "    %time model.fit(dataset, labels)\n",
    "    cents = model.cluster_centers_\n",
    "    asses = model.predict(dataset)\n",
    "    # 14s on 1 titanX pascal with stepdata=1 , k=21 , maxiterations=1000 , whichalgo=1 , whichimage=0\n",
    "    # 26s on 1 titanX maxwell with stepdata=1 , k=21 , maxiterations=1000 , whichalgo=1 , whichimage=0\n",
    "    # 4s on 4 titanX pascals with stepdata=1 , k=21 , maxiterations=1000 , whichalgo=1 , whichimage=0\n",
    "\n",
    "if whichalgo==2:\n",
    "    #hist(dataset)\n",
    "    np.savetxt(\"data.csv\",dataset,delimiter=\",\")\n",
    "    # see /opt/intel/compilers_and_libraries_2017/linux/daal/examples/python/source/kmeans\n",
    "    # source /opt/intel/compilers_and_libraries_2017/linux/daal/bin/daalvars.sh intel64\n",
    "    # cp -a /opt/intel/compilers_and_libraries_2017/linux/daal/examples/python/source/utils  ~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/\n",
    "    # sudo chown -R $USER:$USER /opt/intel\n",
    "    # cd /opt/intel/compilers_and_libraries_2017/linux/daal/pydaal_sources ; python setup.py install\n",
    "    \n",
    "    # 59s with stepdata=1 , k=21 , maxiterations=1000 , whichalgo=2 , whichimage=0 physics.umd.edu\n",
    "    # 50s with stepdata=1 , k=21 , maxiterations=1000 , whichalgo=2 , whichimage=0 pseudotensor\n",
    "    from daal.data_management import (\n",
    "        FileDataSource, DataSourceIface\n",
    "    )\n",
    "    from daal.algorithms.kmeans import (\n",
    "        Batch_Float32LloydDense, init, data, inputCentroids, assignments, centroids, goalFunction\n",
    "    )\n",
    "    from os.path import join as jp\n",
    "    datasetFileName = jp('data.csv')\n",
    "    \n",
    "    import inspect, sys, os.path\n",
    "    utils_folder = os.path.realpath(os.path.abspath(jp(os.path.split(inspect.getfile(inspect.currentframe()))[0], \"..\")))\n",
    "    if utils_folder not in sys.path:\n",
    "        sys.path.insert(0, utils_folder)\n",
    "    from utils import printNumericTable\n",
    "    from utils import isFull\n",
    "        \n",
    "    from daal.data_management import (\n",
    "        CSRNumericTable, NumericTableIface, readOnly, BlockDescriptor,\n",
    "        packed_mask, HomogenNumericTable, KeyValueDataCollection,\n",
    "        DataSourceIface, FileDataSource, HomogenTensor, SubtensorDescriptor,\n",
    "    )\n",
    "\n",
    "    # K-Means algorithm parameters\n",
    "    nClusters = k\n",
    "    nIterations = maxiterations\n",
    "\n",
    "    # Initialize FileDataSource to retrieve the input data from a .csv file\n",
    "    dataSource = FileDataSource(\n",
    "        datasetFileName,\n",
    "        DataSourceIface.doAllocateNumericTable,\n",
    "        DataSourceIface.doDictionaryFromContext\n",
    "    )\n",
    "\n",
    "    # Retrieve the data from the input file\n",
    "    dataSource.loadDataBlock()\n",
    "\n",
    "    # Get initial clusters for the K-Means algorithm (can change Float32 to Float64)\n",
    "    initAlg = init.Batch_Float32RandomDense(nClusters)\n",
    "\n",
    "    initAlg.input.set(init.data, dataSource.getNumericTable())\n",
    "\n",
    "    res = initAlg.compute()\n",
    "    %time centroidsResult = res.get(init.centroids)\n",
    "\n",
    "    # Create an algorithm object for the K-Means algorithm (can change Float32 to Float64)\n",
    "    algorithm = Batch_Float32LloydDense(nClusters, nIterations)\n",
    "\n",
    "    algorithm.input.set(data, dataSource.getNumericTable())\n",
    "    algorithm.input.set(inputCentroids, centroidsResult)\n",
    "\n",
    "    %time res = algorithm.compute()\n",
    "\n",
    "    # Print the clusterization results\n",
    "    asses0 = res.get(assignments)\n",
    "    cents0 = res.get(centroids)\n",
    "\n",
    "    num_rows = asses0.getNumberOfRows()\n",
    "    num_cols = asses0.getNumberOfColumns()\n",
    "    layout = asses0.getDataLayout()\n",
    "    if isFull(layout) or layout == NumericTableIface.csrArray:\n",
    "        datatype=0\n",
    "    else:\n",
    "        datatype=1\n",
    "    print(\"asses: num_rows=%d num_cols=%d datatype=%d\" % (num_rows,num_cols,datatype))\n",
    "    block = BlockDescriptor()\n",
    "    asses0.getBlockOfRows(0, num_rows, readOnly, block)\n",
    "    asses=block.getArray()\n",
    "    \n",
    "    num_rows = cents0.getNumberOfRows()\n",
    "    num_cols = cents0.getNumberOfColumns()\n",
    "    layout = cents0.getDataLayout()\n",
    "    if isFull(layout) or layout == NumericTableIface.csrArray:\n",
    "        datatype=0\n",
    "    else:\n",
    "        datatype=1\n",
    "    print(\"cents: num_rows=%d num_cols=%d datatype=%d\" % (num_rows,num_cols,datatype))\n",
    "    block2 = BlockDescriptor()\n",
    "    cents0.getBlockOfRows(0, num_rows, readOnly, block2)\n",
    "    cents=block2.getArray()\n",
    "    \n",
    "    printNumericTable(res.get(assignments), \"First k cluster assignments:\", k)\n",
    "    printNumericTable(res.get(centroids), \"First 3 dimensions of centroids:\", k, 3)\n",
    "    printNumericTable(res.get(goalFunction), \"Goal function value:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type (dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(asses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ndarray.flatten(asses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams[\"figure.figsize\"] = (10, 10)\n",
    "scatter(dataset[::step, 1], dots.shape[0] - dataset[::step, 0], c=asses[::step], edgecolors=\"none\")\n",
    "scatter(cents[:, 1], dots.shape[0] - cents[:, 0], c=\"black\", s=40, edgecolors=\"none\")\n",
    "xlim((0, dots.shape[1]))\n",
    "ylim((0, dots.shape[0]))\n",
    "axis(\"off\")\n",
    "savefig(\"sourced.png\", transparent=True, bbox_inches=0, pad_inches=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
